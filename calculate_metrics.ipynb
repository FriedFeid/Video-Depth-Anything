{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import tifffile as tiff\n",
    "\n",
    "from video_depth_anything.video_depth import VideoDepthAnything\n",
    "from utils.dc_utils import read_video_frames, save_video\n",
    "from torchinfo import summary\n",
    "from torchvision.transforms import Compose\n",
    "from video_depth_anything.util.transform import Resize, NormalizeImage, PrepareForNet\n",
    "import cv2\n",
    "from thop import profile\n",
    "import torch.profiler as profiler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from einops import rearrange\n",
    "import imageio\n",
    "from natsort import natsorted\n",
    "import subprocess\n",
    "import warnings\n",
    "import re\n",
    "from utils.dc_utils import read_video_frames\n",
    "from utils.util import compute_scale_and_shift\n",
    "from utils.align import DepthMap, frame_align_lstsq\n",
    "from utils.vis_util import visualise_data, visualise_money_plot\n",
    "\n",
    "from video_depth_anything.video_depth import INFER_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load videos gt and get rgb paths: \n",
    "root_dir = '/export/data/ffeiden/data/vkitti_videos'\n",
    "cam = 'Camera_0'\n",
    "device = 'cuda:0'\n",
    "encoder = 'vits' # Alternative 'vitl'\n",
    "generate = False\n",
    "SCENE = ['Scene01']#, 'Scene02', 'Scene06', 'Scene18', 'Scene20']\n",
    "FPS = 25\n",
    "context_length = 32\n",
    "align = False\n",
    "keyframes = ['0', '12']\n",
    "keyframes_name = ''\n",
    "\n",
    "\n",
    "for key_num in keyframes:\n",
    "    keyframes_name += key_num + ','\n",
    "\n",
    "if align:\n",
    "    align_name = '_align'\n",
    "else:\n",
    "    align_name = ''\n",
    "\n",
    "Name = f'SingleImage_{encoder}_con_{context_length}_{align_name}_keyframes_{keyframes}'\n",
    "if os.path.exists(os.path.join(root_dir, Name)):\n",
    "    gen_root_dir = os.path.join(root_dir, Name)\n",
    "    if generate:\n",
    "        warnings.warn('WARNING: You are about to overwrite allready generated Results.')\n",
    "else:\n",
    "    os.mkdir(os.path.join(root_dir, Name))\n",
    "    gen_root_dir = os.path.join(root_dir, Name)\n",
    "\n",
    "vis_methods = ['VDA_s_vits']#, 'VDA_vits', 'DepthAny2_raw', 'DepthAny2']\n",
    "\n",
    "gt_all_data = os.listdir(os.path.join(root_dir, 'gt_vids'))\n",
    "\n",
    "# Sort Data\n",
    "methods = ['DepthAny', 'DepthAny2', 'PrimeDepth']\n",
    "path_dic = {}\n",
    "path_dic['gt'] = natsorted([os.path.join(root_dir, 'gt_vids', p) for p in gt_all_data if cam+'_gt'+'.tiff' in p])\n",
    "for key in methods:\n",
    "    path_dic[key] = natsorted([os.path.join(root_dir, 'gt_vids', p) for p in gt_all_data if key+'_' in p and cam+'.tiff' in p])\n",
    "    path_dic[key+'_raw'] = natsorted([os.path.join(root_dir, 'gt_vids', p) for p in gt_all_data if key+'_' in p and cam+'_raw.tiff' in p])\n",
    "\n",
    "path_dic['rgb'] = [p.replace('_gt.tiff', '.mp4') for p in path_dic['gt']]\n",
    "\n",
    "_, HEIGHT, WIDTH = tiff.imread(path_dic['gt'][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if generate:\n",
    "    # Generate DepthAnythingVideo predictions with supprocess and save them in data \n",
    "    for video_path in path_dic['rgb']:\n",
    "        if align:\n",
    "            subprocess.run([\"python\", \"run.py\", \"--device\", device, \n",
    "                            \"--input_video\", os.path.join(root_dir, 'gt_vids', video_path),\n",
    "                            \"--output_dir\", gen_root_dir,\n",
    "                            \"--save_tiff\", \n",
    "                            \"--save_vis\",\n",
    "                            \"--save_stats\",\n",
    "                            \"--encoder\", encoder,\n",
    "                            \"--keyframe_list\", *keyframes,\n",
    "                            \"--align_each_new_frame\",\n",
    "                            \"--process_single_image\",\n",
    "                            \"--inference_length\", str(context_length)])\n",
    "        else:\n",
    "            subprocess.run([\"python\", \"run.py\", \"--device\", device, \n",
    "                            \"--input_video\", os.path.join(root_dir, 'gt_vids', video_path),\n",
    "                            \"--output_dir\", gen_root_dir,\n",
    "                            \"--save_tiff\", \n",
    "                            \"--save_vis\",\n",
    "                            \"--save_stats\",\n",
    "                            \"--encoder\", encoder,\n",
    "                            \"--keyframe_list\", *keyframes,\n",
    "                            \"--process_single_image\",\n",
    "                            \"--inference_length\", str(context_length)])\n",
    "        \n",
    "        subprocess.run([\"python\", \"run.py\", \"--device\", device, \n",
    "                        \"--input_video\", os.path.join(root_dir, 'gt_vids', video_path),\n",
    "                        \"--output_dir\", gen_root_dir,\n",
    "                        \"--save_tiff\", \n",
    "                        \"--save_vis\",\n",
    "                        \"--save_stats\",\n",
    "                        \"--encoder\", encoder,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Paths:\n",
    "gen_all_data = os.listdir(gen_root_dir)\n",
    "\n",
    "path_dic[f'VDA_s_{encoder}'] = natsorted([os.path.join(gen_root_dir, p) for p in gen_all_data if 'Single_VideoDepthAny_' in p and '_depths.tiff' in p])\n",
    "if len(path_dic[f'VDA_s_{encoder}']) == 0:\n",
    "    warnings.warn('No VideoDepthAny with single image processing found, removed from list', UserWarning)\n",
    "    del path_dic[f'VDA_s_{encoder}']\n",
    "\n",
    "path_dic[f'VDA_{encoder}'] = natsorted([os.path.join(gen_root_dir, p) for p in gen_all_data if 'VideoDepthAny_' in p and '_depths.tiff' in p and 'Single_' not in p])\n",
    "if len(path_dic[f'VDA_{encoder}']) == 0:\n",
    "    warnings.warn('No VideoDepthAny with single image processing found, removed from list', UserWarning)\n",
    "    del path_dic[f'VDA_{encoder}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:30<00:00, 27.06s/it]\n"
     ]
    }
   ],
   "source": [
    "def resize(frame_list):\n",
    "    return np.array([cv2.resize(frame, (WIDTH, HEIGHT), interpolation=cv2.INTER_AREA) for frame in frame_list])\n",
    "\n",
    "# Load data\n",
    "data_dic = {}\n",
    "for key in tqdm(path_dic):\n",
    "    if key != 'rgb':\n",
    "        for p in path_dic[key]:\n",
    "            scene_pattern = re.compile(r\"(Scene\\d+)\")\n",
    "            scene = scene_pattern.search(p).group(1)\n",
    "            data = np.array(tiff.imread(p))\n",
    "            _, height, width = data.shape\n",
    "            if height != HEIGHT or width != WIDTH:\n",
    "                data = resize(data)\n",
    "            data_dic[key+f'_{scene}'] = data\n",
    "        \n",
    "    else:\n",
    "        for p in path_dic[key]:\n",
    "            scene_pattern = re.compile(r\"(Scene\\d+)\")\n",
    "            scene = scene_pattern.search(p).group(1)\n",
    "            data, _ = read_video_frames(p, process_length=-1, target_fps=-1, max_res=-1)\n",
    "            _, height, width, _ = data.shape\n",
    "            if height != HEIGHT or width != WIDTH:\n",
    "                data = resize(data)\n",
    "            data_dic[key+f'_{scene}'] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data_dic: \n",
    "    if '_raw' in key or 'VDA_' in key:\n",
    "        scene_pattern = re.compile(r\"(Scene\\d+)\")\n",
    "        scene = scene_pattern.search(key).group(1)\n",
    "        # We only align on the first frame for now!\n",
    "        if 'VDA_s_' in key:\n",
    "            prediction = data_dic[key][0]\n",
    "            warm_up = len(data_dic[f'gt_{scene}']) - len(data_dic[key])\n",
    "            ground_truth = data_dic[f'gt_{scene}'][warm_up]\n",
    "        else:\n",
    "            prediction = data_dic[key][0]\n",
    "            ground_truth = data_dic[f'gt_{scene}'][0]\n",
    "        \n",
    "        valid_depth = ground_truth < 80.\n",
    "        gt_mask = np.ma.array(ground_truth, mask=~valid_depth)\n",
    "        prediction_mask = np.ma.array(prediction)\n",
    "        # Raw predictions (have to be) are always inverse depth\n",
    "        prediction_tmp = DepthMap(prediction_mask, inverse=True, range=None, scale=None, shift=None)\n",
    "        gt_depth_tmp = DepthMap(gt_mask, inverse=False, range=None, scale=1, shift=0)\n",
    "        # Calculate scale & shift for INVERSE depth\n",
    "        alignment = frame_align_lstsq(prediction_tmp, gt_depth_tmp)\n",
    "        scale, shift = alignment.scale, alignment.shift\n",
    "        \n",
    "        # Use scale & shift to align --> This is still inverse depth here!\n",
    "        data_dic[key] = np.clip((data_dic[key] - shift) / scale, 0., 1.)\n",
    "        \n",
    "        # To make it metric we need to invert it again.\n",
    "        # Avoid division by 0\n",
    "        data_dic[key] = np.where( data_dic[key] == 0., 1e-4, data_dic[key]) \n",
    "        # Clip to max depth \n",
    "        data_dic[key] = np.clip(1. / data_dic[key], 0., 80.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_data(data_dic=data_dic, methods=vis_methods, scene_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_data(data_dic=data_dic, methods=vis_methods, scene_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_data(data_dic=data_dic, methods=vis_methods, scene_idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_data(data_dic=data_dic, methods=vis_methods, scene_idx=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise_data(data_dic=data_dic, methods=vis_methods, scene_idx=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming wamup length of 12\n",
      "Scene01 VDA_s_vits: \n",
      "-----------------------\n",
      "Abs. Error: 3.625\n",
      "MSE Error: 66.677\n",
      "\n",
      "Scene01 VDA_vits: \n",
      "-----------------------\n",
      "Abs. Error: 4.635\n",
      "MSE Error: 84.326\n",
      "\n",
      "Scene01 DepthAny2_raw: \n",
      "-----------------------\n",
      "Abs. Error: 4.306\n",
      "MSE Error: 57.205\n",
      "\n",
      "Scene01 DepthAny2: \n",
      "-----------------------\n",
      "Abs. Error: 2.402\n",
      "MSE Error: 33.227\n",
      "\n",
      "Assuming wamup length of 12\n",
      "Scene02 VDA_s_vits: \n",
      "-----------------------\n",
      "Abs. Error: 2.970\n",
      "MSE Error: 54.797\n",
      "\n",
      "Scene02 VDA_vits: \n",
      "-----------------------\n",
      "Abs. Error: 3.205\n",
      "MSE Error: 57.380\n",
      "\n",
      "Scene02 DepthAny2_raw: \n",
      "-----------------------\n",
      "Abs. Error: 5.068\n",
      "MSE Error: 93.679\n",
      "\n",
      "Scene02 DepthAny2: \n",
      "-----------------------\n",
      "Abs. Error: 2.523\n",
      "MSE Error: 36.432\n",
      "\n",
      "Assuming wamup length of 12\n",
      "Scene06 VDA_s_vits: \n",
      "-----------------------\n",
      "Abs. Error: 2.721\n",
      "MSE Error: 37.135\n",
      "\n",
      "Scene06 VDA_vits: \n",
      "-----------------------\n",
      "Abs. Error: 2.826\n",
      "MSE Error: 35.753\n",
      "\n",
      "Scene06 DepthAny2_raw: \n",
      "-----------------------\n",
      "Abs. Error: 3.829\n",
      "MSE Error: 51.014\n",
      "\n",
      "Scene06 DepthAny2: \n",
      "-----------------------\n",
      "Abs. Error: 2.360\n",
      "MSE Error: 29.503\n",
      "\n",
      "Assuming wamup length of 12\n",
      "Scene18 VDA_s_vits: \n",
      "-----------------------\n",
      "Abs. Error: 3.463\n",
      "MSE Error: 44.095\n",
      "\n",
      "Scene18 VDA_vits: \n",
      "-----------------------\n",
      "Abs. Error: 3.271\n",
      "MSE Error: 41.797\n",
      "\n",
      "Scene18 DepthAny2_raw: \n",
      "-----------------------\n",
      "Abs. Error: 4.059\n",
      "MSE Error: 41.837\n",
      "\n",
      "Scene18 DepthAny2: \n",
      "-----------------------\n",
      "Abs. Error: 3.407\n",
      "MSE Error: 40.793\n",
      "\n",
      "Assuming wamup length of 12\n",
      "Scene20 VDA_s_vits: \n",
      "-----------------------\n",
      "Abs. Error: 3.219\n",
      "MSE Error: 54.182\n",
      "\n",
      "Scene20 VDA_vits: \n",
      "-----------------------\n",
      "Abs. Error: 3.438\n",
      "MSE Error: 56.021\n",
      "\n",
      "Scene20 DepthAny2_raw: \n",
      "-----------------------\n",
      "Abs. Error: 4.145\n",
      "MSE Error: 70.031\n",
      "\n",
      "Scene20 DepthAny2: \n",
      "-----------------------\n",
      "Abs. Error: 2.996\n",
      "MSE Error: 64.816\n",
      "\n",
      "Overall VDA_s_vits: \n",
      "-----------------------\n",
      "Abs. Error: 3.200\n",
      "MSE Error: 51.377\n",
      "\n",
      "Overall VDA_vits: \n",
      "-----------------------\n",
      "Abs. Error: 3.475\n",
      "MSE Error: 55.056\n",
      "\n",
      "Overall DepthAny2_raw: \n",
      "-----------------------\n",
      "Abs. Error: 4.282\n",
      "MSE Error: 62.753\n",
      "\n",
      "Overall DepthAny2: \n",
      "-----------------------\n",
      "Abs. Error: 2.737\n",
      "MSE Error: 40.954\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Metrics_dic = {}\n",
    "for method in vis_methods:\n",
    "    Metrics_dic[method+'_MSE'] = []\n",
    "    Metrics_dic[method+'_Abs'] = []\n",
    "\n",
    "for scene in SCENE:\n",
    "    gt_depth_vid = data_dic['gt_'+scene]\n",
    "    for method in vis_methods:\n",
    "        method_pred = data_dic[method + '_' + scene]\n",
    "        try:\n",
    "            error = np.abs(gt_depth_vid - method_pred).sum() / gt_depth_vid.size\n",
    "            MSE_err = np.mean((method_pred - gt_depth_vid)**2)\n",
    "        except ValueError:\n",
    "            warm_length = len(gt_depth_vid) - len(method_pred)\n",
    "            MSE_err = np.mean((method_pred - gt_depth_vid[warm_length:])**2)\n",
    "            print(f'Assuming wamup length of {warm_length}')\n",
    "            error = np.abs(gt_depth_vid[warm_length:] - method_pred).sum() / gt_depth_vid.size\n",
    "        \n",
    "        print(f'{scene} {method}: ')\n",
    "        print('-----------------------')\n",
    "        print(f'Abs. Error: {error:.3f}')\n",
    "        print(f'MSE Error: {MSE_err:.3f}')\n",
    "        print('')\n",
    "        Metrics_dic[method+'_MSE'].append(MSE_err)\n",
    "        Metrics_dic[method+'_Abs'].append(error)\n",
    "\n",
    "for method in vis_methods:\n",
    "    error = np.mean(Metrics_dic[method+'_Abs'])\n",
    "    MSE_err = np.mean(Metrics_dic[method+'_MSE'])\n",
    "\n",
    "\n",
    "    print(f'Overall {method}: ')\n",
    "    print('-----------------------')\n",
    "    print(f'Abs. Error: {error:.3f}')\n",
    "    print(f'MSE Error: {MSE_err:.3f}')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SingleImage_vits_con_32__align_keyframes_['0', '12']\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "video-depth-any",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
